{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZemljakM/RUAP-projekt/blob/main/EDAandModelTrainingAnimals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install scikit-plot"
      ],
      "metadata": {
        "id": "Z2b-67fC29FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKjLFycjzSyN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Input, BatchNormalization\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "import os\n",
        "import zipfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import scikitplot as skplt\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9SJdAZRzWql"
      },
      "outputs": [],
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "source_path = '/content/kaggle.json'\n",
        "destination_path = '/root/.kaggle/kaggle.json'\n",
        "kaggle_dir = '/root/.kaggle/'\n",
        "if not os.path.exists(kaggle_dir):\n",
        "    os.makedirs(kaggle_dir)\n",
        "os.rename(source_path, destination_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThQDCUW0zDKu"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets download -d alessiocorrado99/animals10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rvuVkkmzkTf"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile('/content/animals10.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall('/content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShslmwWe7h10"
      },
      "outputs": [],
      "source": [
        "def plot_animals(df):\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    df['category_names'] = df['category'].map(animal_mapping)\n",
        "    sns.countplot(data=df, x='category_names', edgecolor='black')\n",
        "    plt.title('Animal Distribution')\n",
        "    plt.xlabel('Animal Category')\n",
        "    plt.ylabel('Count')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnDxI265Q52s"
      },
      "outputs": [],
      "source": [
        "def extract_features(images, height, width):\n",
        "    features = []\n",
        "    for image in tqdm(images):\n",
        "        var_img = load_img(image, color_mode='grayscale')\n",
        "        var_img = var_img.resize((height,width), Image.Resampling.LANCZOS)\n",
        "        var_img = np.array(var_img)\n",
        "        var_img = var_img / 255.0\n",
        "        features.append(var_img)\n",
        "    features = np.array(features)\n",
        "    features = features.reshape(len(features), height, width, 1)\n",
        "    features = np.array(features, dtype=np.float32)\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVySSjghTemG"
      },
      "outputs": [],
      "source": [
        "def display_images(images, labels, num_images=5):\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(1, num_images, i+1)\n",
        "        plt.imshow(images[i+1000], cmap='gray')\n",
        "        plt.title(np.argmax(labels[i+1000]))\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbw0ErdQRK1B"
      },
      "outputs": [],
      "source": [
        "def create_model(input_shape,num_classes):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    conv_1 = Conv2D(32, kernel_size=(3,3), activation='relu', padding='same')(inputs)\n",
        "    batch_1 = BatchNormalization()(conv_1)\n",
        "    conv_2 = Conv2D(64, kernel_size=(3,3), activation='relu', padding='same')(batch_1)\n",
        "    batch_2 = BatchNormalization()(conv_2)\n",
        "\n",
        "    maxpool_1 = MaxPooling2D(pool_size=(2,2))(batch_2)\n",
        "    dropout_1 = Dropout(0.25)(maxpool_1)\n",
        "\n",
        "    conv_3 = Conv2D(128, kernel_size=(3,3), activation='relu', padding='same')(dropout_1)\n",
        "    batch_3 = BatchNormalization()(conv_3)\n",
        "    conv_4 = Conv2D(128, kernel_size=(3,3), activation='relu', padding='same')(batch_3)\n",
        "    batch_4 = BatchNormalization()(conv_4)\n",
        "\n",
        "    maxpool_2 = MaxPooling2D(pool_size=(2,2))(batch_4)\n",
        "    dropout_2 = Dropout(0.25)(maxpool_2)\n",
        "\n",
        "    conv_5 = Conv2D(256, kernel_size=(3,3), activation='relu', padding='same')(dropout_2)\n",
        "    batch_5 = BatchNormalization()(conv_5)\n",
        "    conv_6 = Conv2D(256, kernel_size=(3,3), activation='relu', padding='same')(batch_5)\n",
        "    batch_6 = BatchNormalization()(conv_6)\n",
        "\n",
        "    maxpool_3 = MaxPooling2D(pool_size=(2,2))(batch_6)\n",
        "    dropout_3 = Dropout(0.25)(maxpool_3)\n",
        "\n",
        "    conv_7 = Conv2D(512, kernel_size=(3,3), activation='relu', padding='same', kernel_regularizer=l2(0.01))(dropout_3)\n",
        "    batch_7 = BatchNormalization()(conv_7)\n",
        "    conv_8 = Conv2D(512, kernel_size=(3,3), activation='relu', padding='same', kernel_regularizer=l2(0.01))(batch_7)\n",
        "    batch_8 = BatchNormalization()(conv_8)\n",
        "\n",
        "    maxpool_4 = MaxPooling2D(pool_size=(2,2))(batch_8)\n",
        "    dropout_4 = Dropout(0.25)(maxpool_4)\n",
        "\n",
        "    conv_9 = Conv2D(512, kernel_size=(3,3), activation='relu', padding='same', kernel_regularizer=l2(0.01))(dropout_4)\n",
        "    batch_9 = BatchNormalization()(conv_9)\n",
        "    conv_10 = Conv2D(512, kernel_size=(3,3), activation='relu', padding='same', kernel_regularizer=l2(0.01))(batch_9)\n",
        "    batch_10 = BatchNormalization()(conv_10)\n",
        "\n",
        "    flatten = Flatten()(batch_10)\n",
        "\n",
        "    dense_1 = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(flatten)\n",
        "\n",
        "    dropout1d_1 = Dropout(0.3)(dense_1)\n",
        "\n",
        "    dense_2 = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(dropout1d_1)\n",
        "\n",
        "    output = Dense(num_classes, activation='softmax', name=\"animal_out\")(dense_2)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[output])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WJRIjUS56It"
      },
      "outputs": [],
      "source": [
        "foldernames = os.listdir('/content/raw-img/')\n",
        "categories = []\n",
        "files = []\n",
        "i = 0\n",
        "for k, folder in enumerate(foldernames):\n",
        "    filenames = os.listdir(\"/content/raw-img/\" + folder);\n",
        "    for file in filenames:\n",
        "        files.append(\"/content/raw-img/\" + folder + \"/\" + file)\n",
        "        categories.append(k)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'filename': files,\n",
        "    'category': categories\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixjI5CPx-LtQ"
      },
      "outputs": [],
      "source": [
        "animal_mapping = {\n",
        "    0: 'Krava',\n",
        "    1: 'Leptir',\n",
        "    2: 'Pas',\n",
        "    3: 'Macka',\n",
        "    4: 'Konj',\n",
        "    5: 'Vjeverica',\n",
        "    6: 'Slon',\n",
        "    7: 'Ovca',\n",
        "    8: 'Pauk',\n",
        "    9: 'Kokos'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3bNQbmZ7oWy"
      },
      "outputs": [],
      "source": [
        "plot_animals(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSV8Pv6yRPzB"
      },
      "outputs": [],
      "source": [
        "image_height = 128\n",
        "image_width = 128\n",
        "num_classes = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdizWwxrRSwQ"
      },
      "outputs": [],
      "source": [
        "X = extract_features(df[\"filename\"],image_height,image_width)\n",
        "\n",
        "y = np.array(df[\"category\"])\n",
        "\n",
        "y = np.array(list(df[\"category\"].apply(lambda x: to_categorical(x, num_classes=num_classes))))\n",
        "\n",
        "input_shape = (image_height,image_width,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Lb7v5nHPPtf"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwBWLGHCTjMd"
      },
      "outputs": [],
      "source": [
        "display_images(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fd3yG1ZPPpL"
      },
      "outputs": [],
      "source": [
        "opt = Adam(learning_rate=0.005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g15m8QKcSaCl"
      },
      "outputs": [],
      "source": [
        "# Nas model #\n",
        "\n",
        "model = create_model(input_shape, num_classes)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer = opt, metrics='accuracy' )\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(factor=0.5, patience=5)\n",
        "\n",
        "history = model.fit(x=X_train, y=y_train, batch_size=64, epochs=100, validation_split=0.2, callbacks=[lr_scheduler, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oF5z8TnGPj6S"
      },
      "outputs": [],
      "source": [
        "model.save('animalmodel.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6Z4e9hEYd5W"
      },
      "outputs": [],
      "source": [
        "def display_acc_graph(history):\n",
        "    acc = history.history[\"accuracy\"]\n",
        "    val_acc = history.history[\"val_accuracy\"]\n",
        "    epochs = range(len(acc))\n",
        "    plt.plot(epochs, acc, 'b', label=\"Training Accuracy\")\n",
        "    plt.plot(epochs, val_acc, 'r', label=\"Validation Accuracy\")\n",
        "    plt.title(\"Accuracy Graph\")\n",
        "    plt.legend()\n",
        "    plt.figure()\n",
        "\n",
        "def display_loss_graph(history):\n",
        "    loss = history.history[\"loss\"]\n",
        "    val_loss = history.history[\"val_loss\"]\n",
        "    epochs = range(len(loss))\n",
        "    plt.plot(epochs, loss, 'b', label=\"Training Loss\")\n",
        "    plt.plot(epochs, val_loss, 'r', label=\"Validation Loss\")\n",
        "    plt.title(\"Loss Graph\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARe5sL-VwfTq"
      },
      "outputs": [],
      "source": [
        "display_acc_graph(history)\n",
        "display_loss_graph(history)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "animalmodel = load_model('animalmodel.h5')\n",
        "animalmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "y_pred_animal = animalmodel.predict(X_test)\n",
        "y_pred_animal = y_pred_animal.argmax(axis=1)\n",
        "y_test = y_test.argmax(axis=1)\n",
        "print(classification_report(y_test, y_pred_animal))\n",
        "\n",
        "conf_matrix_age = confusion_matrix(y_test, y_pred_animal)\n",
        "print(conf_matrix_age)\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred_animal, figsize=(8, 6), cmap='Blues')\n",
        "plt.xlabel('Predicted Animal')\n",
        "plt.ylabel('True Animal')\n",
        "plt.title('Confusion Matrix for Animal')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "F7MHErn19Ohy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTTPGiciOoUx"
      },
      "outputs": [],
      "source": [
        "# KNN #\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = X_train.reshape(X_train[0],-1)\n",
        "X_test = X_test.reshape(X_test[0],-1)\n",
        "\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = knn_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StgsaWYfl-AL"
      },
      "outputs": [],
      "source": [
        "conf_matrix_age = confusion_matrix(y_test, y_pred)\n",
        "print(conf_matrix_age)\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred, figsize=(8, 6), cmap='Blues')\n",
        "plt.xlabel('Predicted Animal')\n",
        "plt.ylabel('True Animal')\n",
        "plt.title('Confusion Matrix for Animals')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vjXK5FyOvGH"
      },
      "outputs": [],
      "source": [
        "with open('knn_animal_model.pkl', 'wb') as model_file:\n",
        "    pickle.dump(knn_model, model_file)\n",
        "\n",
        "# with open('knn_model.pkl', 'rb') as model_file:\n",
        "#     knn_model = pickle.load(model_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fIH-6uoO0k1"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/knn_model.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4wdJrujPANO"
      },
      "outputs": [],
      "source": [
        "# MobileNetV2 #\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(3, (1, 1), input_shape=(128, 128, 1)),\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(factor=0.5, patience=5)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2, callbacks=[lr_scheduler, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANFq-Zcatt-A"
      },
      "outputs": [],
      "source": [
        "model.save('mobileanimalmodel.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLfu0eA3t1BF"
      },
      "outputs": [],
      "source": [
        "files.download(\"/content/mobileanimalmodel.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vddhXulquV16"
      },
      "outputs": [],
      "source": [
        "display_acc_graph(history)\n",
        "display_loss_graph(history)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "animalmodel = load_model('mobileanimalmodel.h5')\n",
        "animalmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "y_pred_animal = animalmodel.predict(X_test)\n",
        "y_pred_animal = y_pred_animal.argmax(axis=1)\n",
        "y_test = y_test.argmax(axis=1)\n",
        "\n",
        "print(classification_report(y_test, y_pred_animal))\n",
        "\n",
        "conf_matrix_age = confusion_matrix(y_test, y_pred_animal)\n",
        "print(conf_matrix_age)\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred_animal, figsize=(8, 6), cmap='Blues')\n",
        "plt.xlabel('Predicted Animal')\n",
        "plt.ylabel('True Animal')\n",
        "plt.title('Confusion Matrix for Animals')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gouxSsjfG-NP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4z-XrH2uYT8"
      },
      "outputs": [],
      "source": [
        "# RF #\n",
        "\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(y_train.shape)\n",
        "\n",
        "X_train_flattened = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test_flattened = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=200, criterion='gini', random_state=42)\n",
        "\n",
        "y_train_labels = np.argmax(y_train, axis=1)\n",
        "rf_model.fit(X_train_flattened, y_train_labels)\n",
        "\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "y_pred = rf_model.predict(X_test_flattened)\n",
        "\n",
        "accuracy = accuracy_score(y_test_labels, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "print(classification_report(y_test_labels, y_pred))\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test_labels, y_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}